#!meta

{"kernelInfo":{"defaultKernelName":"csharp","items":[{"aliases":[],"name":"csharp"}]}}

#!csharp

#r "nuget:Microsoft.Data.Analysis"
#r "nuget:Microsoft.ML"
#r "nuget:Microsoft.ML.AutoML"
#r "nuget:Newtonsoft.Json"
#r "nuget:Plotly.NET"
#r "nuget:Plotly.NET.Interactive"

using Microsoft.DotNet.Interactive.Formatting;
using Microsoft.Data.Analysis;
using Microsoft.ML;
using Microsoft.ML.AutoML;
using Microsoft.ML.AutoML.CodeGen;
using Microsoft.ML.SearchSpace;
using Microsoft.ML.SearchSpace.Option;
using Microsoft.ML.Data;
using Microsoft.ML.Trainers;
using Microsoft.ML.Transforms;
using Microsoft.ML.Transforms.Text;
using Newtonsoft.Json;
using System.Reflection;

#!csharp

//#r "nuget:MattEland.ML"
//#r "nuget:MattEland.ML.Charts"
//#r "nuget:MattEland.ML.DataFrames"
//#r "nuget:MattEland.ML.Interactive"
#r "/home/matteland/Documents/MattEland.ML/MattEland.ML/MattEland.ML/bin/Debug/net8.0/MattEland.ML.dll"
#r "/home/matteland/Documents/MattEland.ML/MattEland.ML/MattEland.ML.DataFrames/bin/Debug/net8.0/MattEland.ML.DataFrames.dll"
#r "/home/matteland/Documents/MattEland.ML/MattEland.ML/MattEland.ML.Charts/bin/Debug/net8.0/MattEland.ML.Charts.dll"
#r "/home/matteland/Documents/MattEland.ML/MattEland.ML/MattEland.ML.Interactive/bin/Debug/net8.0/MattEland.ML.Interactive.dll"

using MattEland.ML;
using MattEland.ML.Charts;
using MattEland.ML.DataFrames;
using MattEland.ML.Interactive;

await MattEland.ML.Interactive.InteractiveExtensions.Load(Microsoft.DotNet.Interactive.KernelInvocationContext.Current.HandlingKernel.RootKernel);

#!csharp

DataFrame df = DataFrame.LoadCsv("data/Training.csv", separator: ',', header: true);
df.Columns.Remove("PredictedLabel", "Reasoning", "AuthorId", "AuthorDateUtc", "CommitterId", "CommitterDateUtc", "ParentSha", "Parent2Sha", "DayOfWeek", "Month", "Quarter", "Year", "Hour", "TimeOfDay", "IsWeekend", "Sha", "Source");
df["ActualLabel"].SetName("Label");
df.Sample(5)

#!csharp

MLContext context = new();

var split = context.Data.TrainTestSplit(df, testFraction: 0.3, seed: 42);
var colTypes = df.GetColumnTypes(excludedColumns: new[] { "Label" });
colTypes

#!csharp

var featurizer = context.Auto().Featurizer(df);

#!csharp

// The classifier step tells AutoML what model trainers are enabled. We'll focus on those that don't require scaled data for simplicity at the moment
var classifier = context.Auto().BinaryClassification(
    useFastForest: true, 
    useLgbm: true, 
    useFastTree: true, 
    useLbfgsLogisticRegression: false, 
    useSdcaLogisticRegression: false);

#!csharp

// Now let's run our experiment using our custom pipeline
var experiment = context.Auto().CreateExperiment()
    .SetPipeline(featurizer.Append(classifier))
    .SetDataset(split)
    .SetBinaryClassificationMetric(BinaryClassificationMetric.F1Score, labelColumn: "Label")
    .SetMaxModelToExplore(10);

TrialResult result = await experiment.RunAsync();
ITransformer model = result.Model;
#!transformer-vis model -d 1 -n
Console.WriteLine(model.GetType().FullName);

var enumTransformer = ((IEnumerable<Microsoft.ML.ITransformer>) model);
var textTransformer = enumTransformer.ToList()[2]; 
#!transformer-vis textTransformer -d 1 -n

var scorer = model.Transform(split.TestSet);

// If the model supports calibration, we could use Evaluate instead
var evalResults = context.BinaryClassification.EvaluateNonCalibrated(model.Transform(split.TestSet), labelColumnName: "Label");

// Let's see how it performed
MLCharts.ClassificationReport(evalResults)

#!csharp

// We'll start with a missing value replacer. We shouldn't have any missing values in training, but perhaps the data we're predicting will.
MissingValueReplacingEstimator imputer = context.Transforms.ReplaceMissingValues(
    columns: colTypes.Numeric.Select(c => new InputOutputColumnPair(c, c)).ToArray(), 
    replacementMode: MissingValueReplacingEstimator.ReplacementMode.DefaultValue);

#!csharp

var boolConverter = context.Transforms.Conversion.ConvertType(
    new[] { new InputOutputColumnPair("IsMerge", "IsMerge"), new InputOutputColumnPair("HasDeletedFiles", "HasDeletedFiles"), new InputOutputColumnPair("HasAddedFiles", "HasAddedFiles") },
    outputKind: DataKind.Single);

#!csharp

// The one-hot encoder wasn't bad, I guess. Let's keep it in there.
OneHotEncodingEstimator oneHot = context.Transforms.Categorical.OneHotEncoding(columns: colTypes.Categorical.Select(c => new InputOutputColumnPair(c,c)).ToArray());

#!csharp

// Having a scaler is a good idea for many models, so let's add that in
NormalizingEstimator scaler = context.Transforms.NormalizeMinMax(columns: colTypes.Numeric.Select(c => new InputOutputColumnPair(c, c)).ToArray());

#!csharp

var options = new TextFeaturizingEstimator.Options() {
    OutputTokensColumnName = "MessageTokens",
    StopWordsRemoverOptions = new StopWordsRemovingEstimator.Options() {
        Language = TextFeaturizingEstimator.Language.English,
    },
    WordFeatureExtractor = new WordBagEstimator.Options() {
        NgramLength = 2,
        UseAllLengths = true,
    },
    CharFeatureExtractor = new WordBagEstimator.Options() {
        NgramLength = 3,
        UseAllLengths = true,
    },
    KeepDiacritics = false,
    KeepPunctuations = false,
    KeepNumbers = false,
    CaseMode = TextNormalizingEstimator.CaseMode.Lower,
    Norm = TextFeaturizingEstimator.NormFunction.L2,
};
TextFeaturizingEstimator textFeaturizer = context.Transforms.Text.FeaturizeText("Message", options, "Message");

#!csharp

// Concatenate down to a Features column
ColumnConcatenatingEstimator concat = context.Transforms.Concatenate("Features", inputColumnNames: colTypes.Numeric.Concat(new[] { "MessageTokens" }).ToArray());

#!csharp

// Let's create our pipeline
SweepablePipeline pipeline = imputer
    .Append(boolConverter)
    .Append(oneHot)
    .Append(scaler)
    .Append(textFeaturizer)
    .Append(concat)
    .Append(classifier);

#!csharp

// Now let's run our experiment using our custom pipeline
var experiment = context.Auto().CreateExperiment()
    .SetPipeline(pipeline)
    .SetDataset(split)
    .SetBinaryClassificationMetric(BinaryClassificationMetric.F1Score, labelColumn: "Label")
    .SetMaxModelToExplore(10);

TrialResult result = await experiment.RunAsync();
ITransformer model = result.Model;

var scorer = model.Transform(split.TestSet);

// If the model supports calibration, we could use Evaluate instead
var evalResults = context.BinaryClassification.EvaluateNonCalibrated(model.Transform(split.TestSet), labelColumnName: "Label");

// Let's see how it performed
MLCharts.ClassificationReport(evalResults)

#!csharp

#!pipeline-vis pipeline -d 2 -n
